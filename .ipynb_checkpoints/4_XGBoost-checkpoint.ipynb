{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train, test and validation. \n",
    "- train set: train the model\n",
    "- validation set: hyperparameter tuning\n",
    "- test set: test the model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>units_sold</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>badges_count</th>\n",
       "      <th>badge_product_quality</th>\n",
       "      <th>product_variation_inventory</th>\n",
       "      <th>merchant_rating_count</th>\n",
       "      <th>merchant_rating</th>\n",
       "      <th>merchant_has_profile_picture</th>\n",
       "      <th>...</th>\n",
       "      <th>rating_one_count</th>\n",
       "      <th>size_m</th>\n",
       "      <th>size_other</th>\n",
       "      <th>size_s</th>\n",
       "      <th>size_xs</th>\n",
       "      <th>log_units_sold</th>\n",
       "      <th>tag_summer</th>\n",
       "      <th>tag_women's fashion</th>\n",
       "      <th>tag_sexy</th>\n",
       "      <th>tag_tank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3.76</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>568</td>\n",
       "      <td>4.128521</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.605170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>3.45</td>\n",
       "      <td>6135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>17752</td>\n",
       "      <td>3.899673</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.903488</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3.57</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>295</td>\n",
       "      <td>3.989831</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.605170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  units_sold  rating  rating_count  badges_count  \\\n",
       "0   16.0         100    3.76            54             0   \n",
       "1    8.0       20000    3.45          6135             0   \n",
       "2    8.0         100    3.57            14             0   \n",
       "\n",
       "   badge_product_quality  product_variation_inventory  merchant_rating_count  \\\n",
       "0                      0                           50                    568   \n",
       "1                      0                           50                  17752   \n",
       "2                      0                            1                    295   \n",
       "\n",
       "   merchant_rating  merchant_has_profile_picture  ...  rating_one_count  \\\n",
       "0         4.128521                             0  ...               9.0   \n",
       "1         3.899673                             0  ...            1077.0   \n",
       "2         3.989831                             0  ...               3.0   \n",
       "\n",
       "   size_m  size_other  size_s  size_xs  log_units_sold  tag_summer  \\\n",
       "0       1           0       0        0        4.605170           1   \n",
       "1       0           0       0        1        9.903488           1   \n",
       "2       0           0       0        1        4.605170           1   \n",
       "\n",
       "   tag_women's fashion  tag_sexy  tag_tank  \n",
       "0                    1         0         0  \n",
       "1                    1         1         0  \n",
       "2                    1         1         0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df = pd.read_csv('data/wish_sales_explore.csv')\n",
    "sales_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sales_df[\"log_units_sold\"]\n",
    "X = sales_df.drop([\"units_sold\",\"log_units_sold\"], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "num_col =[ 'price', 'rating', 'rating_count', 'badges_count',\n",
    "       'product_variation_inventory','merchant_rating_count', 'merchant_rating','rating_five_count',\n",
    "       'rating_four_count', 'rating_three_count', 'rating_two_count',\n",
    "       'rating_one_count']\n",
    "scaler.fit(X_train[num_col]) #fit the min_max scalar on the train dataset \n",
    "\n",
    "def minmax_on_dataset(scaler, df, num_col):\n",
    "    num_scale = scaler.transform(df[num_col])\n",
    "\n",
    "    num_scale_df = pd.DataFrame(num_scale, columns = num_col)\n",
    "    cat_df = df.drop(num_col, axis=1)\n",
    "\n",
    "    num_scale_df.reset_index(drop=True,inplace=True)\n",
    "    cat_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    result_df = pd.concat([num_scale_df, cat_df], axis=1)\n",
    "    return result_df\n",
    "\n",
    "X_train_prep = minmax_on_dataset(scaler, X_train, num_col)\n",
    "X_test_prep = minmax_on_dataset(scaler, X_test, num_col)\n",
    "X_val_prep = minmax_on_dataset(scaler, X_val, num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the splitted datasets to local\n",
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "pd.DataFrame(X_test_prep).to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)\n",
    "\n",
    "y_val.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "X_val_prep.reset_index(drop=True,inplace=True)\n",
    "X_train_prep.reset_index(drop=True,inplace=True)\n",
    "\n",
    "pd.concat([y_val, X_val_prep], axis=1).to_csv(os.path.join(data_dir, 'validation.csv'), header=False, index=False)\n",
    "pd.concat([y_train, X_train_prep], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep = X_val_prep = y_train = y_val = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload training/valdiation data files to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session() # Store the current SageMaker session\n",
    "role = get_execution_role()\n",
    "\n",
    "prefix = 'wish-xgboost'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tuned XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "container = get_image_uri(session.boto_region_name, 'xgboost', repo_version='1.0-1')\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                   role,\n",
    "                                   train_instance_count=1,\n",
    "                                   train_instance_type='ml.m4.xlarge',\n",
    "                                   output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                   sagemaker_session=session)\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                       eta=0.2,\n",
    "                       gamma=4,\n",
    "                       min_child_weight=6,\n",
    "                       subsample=0.8,\n",
    "                       objective='reg:squarederror',\n",
    "                       early_stopping_rounds=10,\n",
    "                       num_round=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and fit the hyperparameter tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator=xgb,\n",
    "                                              objective_metric_name='validation:rmse',\n",
    "                                              objective_type='Minimize',\n",
    "                                              max_jobs=10,\n",
    "                                              max_parallel_jobs=2,\n",
    "                                              hyperparameter_ranges={\n",
    "                                                  'max_depth': IntegerParameter(3,12),\n",
    "                                                  'eta': ContinuousParameter(0.05, 0.5),\n",
    "                                                  'min_child_weight': IntegerParameter(2,8),\n",
    "                                                  'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                  'gamma': ContinuousParameter(0,10)\n",
    "                                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})\n",
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrive the best-performed model and do batch-transform on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-28 20:41:28 Starting - Preparing the instances for training\n",
      "2020-09-28 20:41:28 Downloading - Downloading input data\n",
      "2020-09-28 20:41:28 Training - Training image download completed. Training in progress.\n",
      "2020-09-28 20:41:28 Uploading - Uploading generated training model\n",
      "2020-09-28 20:41:28 Completed - Training job completed\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter _tuning_objective_metric value validation:rmse to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value reg:squarederror to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[20:41:18] 923x22 matrix with 20306 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[20:41:18] 308x22 matrix with 6776 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Setting up HPO optimized metric to be : rmse\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 923 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 308 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:5.58899#011validation-rmse:5.78184\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:4.85573#011validation-rmse:5.04073\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:4.21325#011validation-rmse:4.39216\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:3.66801#011validation-rmse:3.83438\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:3.19790#011validation-rmse:3.34962\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:2.78939#011validation-rmse:2.92632\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:2.44255#011validation-rmse:2.57352\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:2.14210#011validation-rmse:2.25985\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:1.88378#011validation-rmse:1.99355\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:1.66422#011validation-rmse:1.76510\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:1.47467#011validation-rmse:1.57189\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:1.31221#011validation-rmse:1.40470\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:1.17837#011validation-rmse:1.27500\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:1.06568#011validation-rmse:1.16518\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.97041#011validation-rmse:1.06872\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.89471#011validation-rmse:0.99503\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.83118#011validation-rmse:0.93518\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.77617#011validation-rmse:0.88220\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.72994#011validation-rmse:0.83978\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.69849#011validation-rmse:0.80987\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.66854#011validation-rmse:0.78057\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.64249#011validation-rmse:0.75217\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.62726#011validation-rmse:0.73796\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.61069#011validation-rmse:0.72320\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.59729#011validation-rmse:0.71330\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.58991#011validation-rmse:0.70605\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.57703#011validation-rmse:0.69908\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.56995#011validation-rmse:0.69556\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.56110#011validation-rmse:0.69391\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.55885#011validation-rmse:0.69199\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.55007#011validation-rmse:0.69089\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.54752#011validation-rmse:0.69049\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.54673#011validation-rmse:0.68986\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.54323#011validation-rmse:0.68559\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:0.54276#011validation-rmse:0.68523\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:0.53948#011validation-rmse:0.68403\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:0.53854#011validation-rmse:0.68325\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:0.53817#011validation-rmse:0.68299\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:0.53637#011validation-rmse:0.68263\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:0.53176#011validation-rmse:0.68423\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:0.52886#011validation-rmse:0.68490\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:0.52872#011validation-rmse:0.68481\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:0.52860#011validation-rmse:0.68474\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:0.52525#011validation-rmse:0.68352\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:0.52370#011validation-rmse:0.68471\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:0.52367#011validation-rmse:0.68470\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:0.52125#011validation-rmse:0.68350\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:0.51999#011validation-rmse:0.68243\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:0.51999#011validation-rmse:0.68243\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:0.51998#011validation-rmse:0.68244\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:0.51680#011validation-rmse:0.68065\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:0.51680#011validation-rmse:0.68067\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:0.51519#011validation-rmse:0.67993\u001b[0m\n",
      "\u001b[34m[53]#011train-rmse:0.51519#011validation-rmse:0.67996\u001b[0m\n",
      "\u001b[34m[54]#011train-rmse:0.51519#011validation-rmse:0.67995\u001b[0m\n",
      "\u001b[34m[55]#011train-rmse:0.51519#011validation-rmse:0.67997\u001b[0m\n",
      "\u001b[34m[56]#011train-rmse:0.51519#011validation-rmse:0.67994\u001b[0m\n",
      "\u001b[34m[57]#011train-rmse:0.51150#011validation-rmse:0.67922\u001b[0m\n",
      "\u001b[34m[58]#011train-rmse:0.51150#011validation-rmse:0.67923\u001b[0m\n",
      "\u001b[34m[59]#011train-rmse:0.51150#011validation-rmse:0.67921\u001b[0m\n",
      "\u001b[34m[60]#011train-rmse:0.51152#011validation-rmse:0.67920\u001b[0m\n",
      "\u001b[34m[61]#011train-rmse:0.51152#011validation-rmse:0.67920\u001b[0m\n",
      "\u001b[34m[62]#011train-rmse:0.51153#011validation-rmse:0.67920\u001b[0m\n",
      "\u001b[34m[63]#011train-rmse:0.51150#011validation-rmse:0.67921\u001b[0m\n",
      "\u001b[34m[64]#011train-rmse:0.50926#011validation-rmse:0.68091\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:0.50928#011validation-rmse:0.68090\u001b[0m\n",
      "\u001b[34m[66]#011train-rmse:0.50929#011validation-rmse:0.68089\u001b[0m\n",
      "\u001b[34m[67]#011train-rmse:0.50432#011validation-rmse:0.68340\u001b[0m\n",
      "\u001b[34m[68]#011train-rmse:0.50256#011validation-rmse:0.68301\u001b[0m\n",
      "\u001b[34m[69]#011train-rmse:0.50250#011validation-rmse:0.68300\u001b[0m\n",
      "\u001b[34m[70]#011train-rmse:0.50248#011validation-rmse:0.68300\u001b[0m\n",
      "\u001b[34m[71]#011train-rmse:0.49941#011validation-rmse:0.68244\u001b[0m\n",
      "\u001b[34m[72]#011train-rmse:0.49772#011validation-rmse:0.68382\u001b[0m\n",
      "Training seconds: 59\n",
      "Billable seconds: 59\n"
     ]
    }
   ],
   "source": [
    "xgb_attached = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[32m2020-09-28T20:54:16.725:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2020-09-28:20:54:14:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2020-09-28:20:54:14:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2020-09-28:20:54:14:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[35m[2020-09-28:20:54:14:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2020-09-28:20:54:14:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2020-09-28:20:54:14:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020/09/28 20:54:14 [crit] 20#20: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [28/Sep/2020:20:54:14 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/28 20:54:14 [crit] 20#20: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [28/Sep/2020:20:54:14 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-09-28 20:54:14 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2020-09-28 20:54:14 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[34m[2020-09-28 20:54:14 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-09-28 20:54:14 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2020-09-28 20:54:14 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2020-09-28 20:54:14 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2020-09-28 20:54:14 +0000] [32] [INFO] Booting worker with pid: 32\u001b[0m\n",
      "\u001b[34m[2020-09-28:20:54:16:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [28/Sep/2020:20:54:16 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [28/Sep/2020:20:54:16 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2020/09/28 20:54:14 [crit] 20#20: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [28/Sep/2020:20:54:14 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/28 20:54:14 [crit] 20#20: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [28/Sep/2020:20:54:14 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2020-09-28 20:54:14 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2020-09-28 20:54:14 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[35m[2020-09-28 20:54:14 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-09-28 20:54:14 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2020-09-28 20:54:14 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[35m[2020-09-28 20:54:14 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[35m[2020-09-28 20:54:14 +0000] [32] [INFO] Booting worker with pid: 32\u001b[0m\n",
      "\u001b[35m[2020-09-28:20:54:16:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [28/Sep/2020:20:54:16 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [28/Sep/2020:20:54:16 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-09-28:20:54:16:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [28/Sep/2020:20:54:16 +0000] \"POST /invocations HTTP/1.1\" 200 5534 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2020-09-28:20:54:16:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [28/Sep/2020:20:54:16 +0000] \"POST /invocations HTTP/1.1\" 200 5534 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer = xgb_attached .transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 5.4 KiB/5.4 KiB (95.6 KiB/s) with 1 file(s) remaining\r",
      "download: s3://sagemaker-us-east-2-668015539882/sagemaker-xgboost-200928-2025-009-c5ae0-2020-09-28-20-49-34-958/test.csv.out to data/test.csv.out\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6503359194361048"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, predictions.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the hyperparametering tuning, the XGBoost's accuracy increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1350.4417627509126"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(np.exp(y_test), np.exp(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
